{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing libraries and datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Importing torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# check if we have cuda installed\n",
    "if torch.cuda.is_available():\n",
    "    # to use GPU\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('GPU is:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Importing language detection\n",
    "\n",
    "- For Malay, we use dictionaries from IPA-Dict and Dewan Bahasa.\n",
    "- For English, we use NLTK corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "\n",
    "# my_raw1 = json.load(open('../dictionary/200k-english-malay.json'))\n",
    "# my_raw2 = open('../dictionary/en-ms.txt', encoding=\"utf8\")\n",
    "# my_raw3 = open('../dictionary/malay-ipa-dict.txt', encoding=\"utf8\")\n",
    "\n",
    "# my_raw1 = [x[1] for x in my_raw1]\n",
    "# my_raw2 = [x.split('\\t')[1].strip() for x in my_raw2.readlines()]\n",
    "# my_raw3 = [x.split('\\t')[0] for x in my_raw3.readlines()]\n",
    "\n",
    "# with open('../dictionary/combined-malay-dict.txt', 'w', encoding=\"utf8\") as fp:\n",
    "#     for item in sorted(list(dict.fromkeys(my_raw1 + my_raw2 + my_raw3))):\n",
    "#         if item:\n",
    "#             fp.write(\"%s\\n\" % item)\n",
    "\n",
    "with open('../dictionary/combined-malay-dict.txt', encoding=\"utf8\") as fp:\n",
    "    malay_dict = [x.strip() for x in fp.readlines()]\n",
    "    \n",
    "def detect_malay(text): return text in malay_dict\n",
    "def detect_english(text): return text in nltk.corpus.words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Importing and combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Menggelabah masing-masing nak beraya kan. Lepa...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.999371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bendera putih tu bukannya nak harap bantuan ke...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.999432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nape nak kena tampal gambar Dia pulak...Guna d...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.999458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sudah sudah la kak mas woi. Kamu tahu tak semu...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.999358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kerajaan kita bukan serba boleh, tapi serba bo...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.999450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23024</th>\n",
       "      <td>@hannahyeoh Terbaik MP Segambut kan gitu... Ka...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.999410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23025</th>\n",
       "      <td>Time ph pon byk aset terjual yb.. time tue yb ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.999405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23026</th>\n",
       "      <td>bila jadi pembangkang auto savage hshshshsh ta...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.999365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23027</th>\n",
       "      <td>PAN ni pun bangang... Inisiatif bendera putih ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.999460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23028</th>\n",
       "      <td>Kerajaan Sarawak bersetuju untuk melaksanakan ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.999012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23029 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label      prob\n",
       "0      Menggelabah masing-masing nak beraya kan. Lepa...  Negative  0.999371\n",
       "1      Bendera putih tu bukannya nak harap bantuan ke...  Negative  0.999432\n",
       "2      Nape nak kena tampal gambar Dia pulak...Guna d...  Negative  0.999458\n",
       "3      Sudah sudah la kak mas woi. Kamu tahu tak semu...  Negative  0.999358\n",
       "4      Kerajaan kita bukan serba boleh, tapi serba bo...  Negative  0.999450\n",
       "...                                                  ...       ...       ...\n",
       "23024  @hannahyeoh Terbaik MP Segambut kan gitu... Ka...  Negative  0.999410\n",
       "23025  Time ph pon byk aset terjual yb.. time tue yb ...  Negative  0.999405\n",
       "23026  bila jadi pembangkang auto savage hshshshsh ta...  Negative  0.999365\n",
       "23027  PAN ni pun bangang... Inisiatif bendera putih ...  Negative  0.999460\n",
       "23028  Kerajaan Sarawak bersetuju untuk melaksanakan ...  Positive  0.999012\n",
       "\n",
       "[23029 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # install pandas\n",
    "# !pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# importing datasets\n",
    "\n",
    "# local-new: text + label\n",
    "df = pd.read_csv(r'../data/malaya/local-news.csv')\n",
    "df\n",
    "\n",
    "# semisupervised-bert-xlnet: text + label + prb\n",
    "df = pd.read_csv(r'../data/malaya/semisupervised-bert-xlnet.csv')\n",
    "df\n",
    "\n",
    "# semisupervised-bert-xlnet: text + label + prb\n",
    "df = pd.read_csv(r'../data/malaya/semisupervised-politics-bert-xlnet.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lebih-lebih lagi dengan  kemudahan internet dan laman sosial taktik ini semakin mudah dikembangkan'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unidecode import unidecode\n",
    "import string\n",
    "import re\n",
    "\n",
    "punctuation = '‘’“”!$%&\\()*+,./:;<=>?[\\\\]^_`{|}~•@…'\n",
    "\n",
    "def clean_text(text):\n",
    "    # convert characters to ascii\n",
    "    text = unidecode(text)\n",
    "    \n",
    "    # remove words that is hashtags, mentions and links\n",
    "    text = re.sub(r'^([@#]|http|https)[^\\s]*', '', text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = text.translate(text.maketrans('', '', punctuation))\n",
    "    \n",
    "    # lowercasing text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # stripping text\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "    \n",
    "clean_text(df['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import modeling_bert\n",
    "\n",
    "from modeling_bert import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_id2num = { 'special_token': 0, 'english': 1, 'malay': 2, 'other': 3 }\n",
    "lang_num2id = {v:k for k,v in lang_id2num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"She sells\"\n",
    "# if we tokenize it, this becomes:\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "encoding['language_ids'] = torch.tensor([[0, 0, 0, 0]])\n",
    "\n",
    "print(encoding['input_ids'])\n",
    "\n",
    "for input_id in encoding['input_ids']:\n",
    "    print(tokenizer.decode(input_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "outputs = model(**encoding)\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e07e2cad301f10046f31ca6b8439b04dc67a22fe5bd747bca8a9458062e70f77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
