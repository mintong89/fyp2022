{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427ca465",
   "metadata": {},
   "source": [
    "# Importing and combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1264a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # install pandas\n",
    "# !pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# local-new: text + label*\n",
    "df = pd.read_csv(r'dmalaya/local-news.csv')\n",
    "combined_df = pd.concat([combined_df, df[['text', 'label']].rename(columns={'label': 'sentiment'})])\n",
    "\n",
    "# semisupervised-bert-xlnet: text + label*\n",
    "df = pd.read_csv(r'malaya/semisupervised-bert-xlnet.csv')\n",
    "combined_df = pd.concat([combined_df, df[['text', 'label']].rename(columns={'label': 'sentiment'})])\n",
    "\n",
    "# semisupervised-bert-xlnet: text + label*\n",
    "df = pd.read_csv(r'malaya/semisupervised-politics-bert-xlnet.csv')\n",
    "combined_df = pd.concat([combined_df, df[['text', 'label']].rename(columns={'label': 'sentiment'})])\n",
    "\n",
    "# supervised-data: text + sentiment* \n",
    "df = pd.read_csv(r'malaya/supervised-data.csv', sep='\\t')\n",
    "combined_df = pd.concat([combined_df, df[['text', 'sentiment']]])\n",
    "\n",
    "# supervised-data-politics: text + sentiment* \n",
    "df = pd.read_csv(r'malaya/supervised-data-politics.csv', sep='\\t')\n",
    "combined_df = pd.concat([combined_df, df[['text', 'sentiment']]])\n",
    "\n",
    "# supervised-data-politics: text + sentiment* \n",
    "df = pd.read_csv(r'malaya/manglish.csv', sep='\\t')\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: x.capitalize())\n",
    "combined_df = pd.concat([combined_df, df[['text', 'sentiment']]])\n",
    "\n",
    "# twitter: text + sentiment* \n",
    "df = pd.read_csv(r'scrapping/twitter.csv', sep='\\t')\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: x.capitalize())\n",
    "combined_df = pd.concat([combined_df, df[['text', 'sentiment']]])\n",
    "\n",
    "combined_df = combined_df[combined_df['text'].notnull()].reset_index()[['text', 'sentiment']]\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1488a4",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c54354",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1cfd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "import string\n",
    "import re\n",
    "\n",
    "punctuation = '‘’“”!$%&\\()*+,./:;<=>?[\\\\]^_`{|}~•@…'\n",
    "\n",
    "def clean_text(text):\n",
    "    # convert characters to ascii\n",
    "    text = unidecode(text)\n",
    "    \n",
    "    # remove words that is hashtags, mentions and links\n",
    "    text = re.sub(r'^([@#]|http|https)[^\\s]*', '', text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = text.translate(text.maketrans('', '', punctuation))\n",
    "    \n",
    "    # remove next line     \n",
    "    text = re.sub('\\n', '', text)\n",
    "    \n",
    "    # lowercasing text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # stripping text\n",
    "    text = text.strip()\n",
    "    \n",
    "    # remove words containing numbers\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    return text\n",
    "    \n",
    "combined_df['text'] = combined_df['text'].apply(lambda x: clean_text(x))\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b01fcc",
   "metadata": {},
   "source": [
    "## Normalise short-form words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "malaya_sf = pd.read_csv(r'../normalise/malaya.csv')\n",
    "cilisos_sf = pd.read_csv(r'../normalise/cilisos.csv', encoding='ISO-8859-1')\n",
    "\n",
    "combined_sf = {x[0]: x[1] for x in malaya_sf.values.tolist() + cilisos_sf.values.tolist()}\n",
    "\n",
    "def normalise_text(text):\n",
    "    return ' '.join([combined_sf[x] if x in combined_sf.keys() else x for x in text.split()])\n",
    "\n",
    "combined_df['text'] = combined_df['text'].apply(lambda x: normalise_text(x))\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01d921",
   "metadata": {},
   "source": [
    "## Clean null and meaningless values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(r'combined_data.csv', sep='\\t', encoding='ISO-8859-1')\n",
    "combined_df = pd.read_csv(r'combined_data.csv', sep='\\t', encoding='ISO-8859-1')\n",
    "\n",
    "# filter text that is at least 5 words and not null\n",
    "combined_df = combined_df[combined_df['text'].apply(lambda x: type(x) is str and len(x.split()) > 5)].reset_index()[['text', 'sentiment']]\n",
    "\n",
    "# filter sentiment that is not null\n",
    "combined_df = combined_df[combined_df['sentiment'].apply(lambda x: type(x) is str)].reset_index()[['text', 'sentiment']]\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd356abc",
   "metadata": {},
   "source": [
    "## Saving datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06204cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(r'combined_data.csv', sep='\\t', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbce361",
   "metadata": {},
   "source": [
    "## Sample datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee4efd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maybe he knew how banyak saya loves u things s...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>betulkan kerajaan sekarang di tanah air sendiri</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jadi this is what saya meant</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>selangortv pakej kita selangor bukti prihatin ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lepas itu dia papp papp paap appl yang dahulu ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>habis lepas ini hendak buang mase dekat mana p...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>mp bn umum kekal sokong pm muhyiddinyassin wal...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>untuk pandan sk tasik permai ampang selangor##</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>can't imagine pokka now like wear green hat</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>a baik summary untuk comparison saya read on t...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text sentiment\n",
       "0       maybe he knew how banyak saya loves u things s...  Negative\n",
       "1         betulkan kerajaan sekarang di tanah air sendiri  Negative\n",
       "2                            jadi this is what saya meant  Negative\n",
       "3       selangortv pakej kita selangor bukti prihatin ...  Negative\n",
       "4       lepas itu dia papp papp paap appl yang dahulu ...  Negative\n",
       "...                                                   ...       ...\n",
       "149995  habis lepas ini hendak buang mase dekat mana p...  Negative\n",
       "149996  mp bn umum kekal sokong pm muhyiddinyassin wal...  Negative\n",
       "149997     untuk pandan sk tasik permai ampang selangor##   Neutral\n",
       "149998        can't imagine pokka now like wear green hat   Neutral\n",
       "149999  a baik summary untuk comparison saya read on t...  Negative\n",
       "\n",
       "[150000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "combined_df = pd.read_csv(r'combined_data.csv', sep='\\t', encoding='ISO-8859-1')\n",
    "\n",
    "sampled_df = combined_df.groupby('sentiment').sample(n=50000).sample(frac=1)\n",
    "sampled_df = sampled_df.reset_index()[['text', 'sentiment']]\n",
    "\n",
    "sampled_df.to_csv(r'sampled_data.csv', sep='\\t', encoding='ISO-8859-1')\n",
    "sampled_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e07e2cad301f10046f31ca6b8439b04dc67a22fe5bd747bca8a9458062e70f77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
