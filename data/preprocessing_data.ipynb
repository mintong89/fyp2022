{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427ca465",
   "metadata": {},
   "source": [
    "# Importing and combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1264a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # install pandas\n",
    "# !pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# local-new: text + label*\n",
    "df = pd.read_csv(r'dmalaya/local-news.csv')\n",
    "combined_df = pd.concat([combined_df, df[['text', 'label']].rename(columns={'label': 'sentiment'})])\n",
    "\n",
    "# semisupervised-bert-xlnet: text + label*\n",
    "df = pd.read_csv(r'malaya/semisupervised-bert-xlnet.csv')\n",
    "combined_df = pd.concat([combined_df, df[['text', 'label']].rename(columns={'label': 'sentiment'})])\n",
    "\n",
    "# semisupervised-bert-xlnet: text + label*\n",
    "df = pd.read_csv(r'malaya/semisupervised-politics-bert-xlnet.csv')\n",
    "combined_df = pd.concat([combined_df, df[['text', 'label']].rename(columns={'label': 'sentiment'})])\n",
    "\n",
    "# supervised-data: text + sentiment* \n",
    "df = pd.read_csv(r'malaya/supervised-data.csv', sep='\\t')\n",
    "combined_df = pd.concat([combined_df, df[['text', 'sentiment']]])\n",
    "\n",
    "# supervised-data-politics: text + sentiment* \n",
    "df = pd.read_csv(r'malaya/supervised-data-politics.csv', sep='\\t')\n",
    "combined_df = pd.concat([combined_df, df[['text', 'sentiment']]])\n",
    "\n",
    "# supervised-data-politics: text + sentiment* \n",
    "df = pd.read_csv(r'malaya/manglish.csv', sep='\\t')\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: x.capitalize())\n",
    "combined_df = pd.concat([combined_df, df[['text', 'sentiment']]])\n",
    "\n",
    "# twitter: text + sentiment* \n",
    "df = pd.read_csv(r'scrapping/twitter.csv', sep='\\t')\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: x.capitalize())\n",
    "combined_df = pd.concat([combined_df, df[['text', 'sentiment']]])\n",
    "\n",
    "combined_df = combined_df[combined_df['text'].notnull()].reset_index()[['text', 'sentiment']]\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1488a4",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c54354",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1cfd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "import string\n",
    "import re\n",
    "\n",
    "punctuation = '‘’“”!$%&\\()*+,./:;<=>?[\\\\]^_`{|}~•@…'\n",
    "\n",
    "def clean_text(text):\n",
    "    # convert characters to ascii\n",
    "    text = unidecode(text)\n",
    "    \n",
    "    # remove words that is hashtags, mentions and links\n",
    "    text = re.sub(r'^([@#]|http|https)[^\\s]*', '', text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = text.translate(text.maketrans('', '', punctuation))\n",
    "    \n",
    "    # remove next line     \n",
    "    text = re.sub('\\n', '', text)\n",
    "    \n",
    "    # lowercasing text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # stripping text\n",
    "    text = text.strip()\n",
    "    \n",
    "    # remove words containing numbers\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    return text\n",
    "    \n",
    "combined_df['text'] = combined_df['text'].apply(lambda x: clean_text(x))\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b01fcc",
   "metadata": {},
   "source": [
    "## Normalise short-form words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "malaya_sf = pd.read_csv(r'../normalise/malaya.csv')\n",
    "cilisos_sf = pd.read_csv(r'../normalise/cilisos.csv', encoding='ISO-8859-1')\n",
    "\n",
    "combined_sf = {x[0]: x[1] for x in malaya_sf.values.tolist() + cilisos_sf.values.tolist()}\n",
    "\n",
    "def normalise_text(text):\n",
    "    return ' '.join([combined_sf[x] if x in combined_sf.keys() else x for x in text.split()])\n",
    "\n",
    "combined_df['text'] = combined_df['text'].apply(lambda x: normalise_text(x))\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd356abc",
   "metadata": {},
   "source": [
    "## Saving datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06204cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(r'combined_data.csv', sep='\\t', encoding='ISO-8859-1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
